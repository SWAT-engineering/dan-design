\RequirePackage[l2tabu, orthodox]{nag}
\RequirePackage[T1]{fontenc}
\RequirePackage[utf8]{inputenc}
\documentclass[10pt,oneside]{article}
\usepackage[margin=2.5cm,foot=2em,head=0pt]{geometry}

\usepackage[dutch]{babel}
\usepackage{csquotes}
\usepackage[largesc,tabular]{newpxtext}
\usepackage[smallerops]{newpxmath}
\linespread{1.05}
\useosf{}
\useproportional{}
\usepackage[scaled=0.8]{beramono}
\AtBeginEnvironment{tabular}{\lfstyle}
\usepackage[babel, final,tracking=true]{microtype}
\usepackage{eurosym}

\usepackage{booktabs}
\usepackage{enumitem}
\setlist{noitemsep, topsep=0pt}
\usepackage{parskip}

\usepackage{longtable}

\usepackage[pdfusetitle]{hyperref}
\usepackage{lastpage}
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\rhead{ 
    \includegraphics[height=5mm]{logo.pdf}
}

\cfoot{
    Initial DSL design of DAN
}
\rfoot{\thepage/\pageref{LastPage}}
\usepackage{etoolbox}
\usepackage{relsize}
\usepackage[printonlyused,nohyperlinks,smaller]{acronym}
\newcommand{\formatac}[1]{\textls[50]{\textsc{#1}}}
\newcommand{\singleAC}[1]{\formatac{\texorpdfstring{\MakeLowercase{#1}}{#1}}}
\newcommand{\singleACp}[1]{\formatac{\texorpdfstring{\MakeLowercase{#1}}{#1}\textsmaller{s}}}
\renewcommand*{\acsfont}[1]{\formatac{\texorpdfstring{\MakeLowercase{#1}}{#1}}}
\makeatletter
\renewcommand*\AC@aclp[1]{\AC@acl{#1}\textsmaller{s}}
\renewcommand*\AC@acsp[1]{\AC@acs{#1}\textsmaller{s}}
\makeatother

\acrodef{DSL}{Domain Specific Language}
\acrodef{SWAT}{Software Analysis and Transformation}

\usepackage{xspace}
\usepackage{tikz}
\definecolor{dotBlue}{rgb/cmyk}{0.1471275,0.5465782,0.8220493/0.7809415,0.4065766,0.0000000,0.0000000}% blue for engineering
\newcommand{\SWATeng}{\singleAC{SWAT}.engineering\xspace}

\usepackage{dblfnote} % double column footnotes for space
\DFNalwaysdouble % for this example

\begin{document}\thispagestyle{empty}

%\vspace*{-4ex}
\begin{center}
    \includegraphics[width=0.6\linewidth]{logo.pdf}\\
\end{center}

\hypertarget{dan----a-dsl-that-targets-metal}{%
\section*{DAN -- A DSL that targets
Metal}\label{dan----a-dsl-that-targets-metal}}

The Netherlands Forensic Institute (NFI) is the national forensics
institute of the Netherlands. Due to advance of digitalization in all
layers of society, the role of the NFI has been quickly evolving in the
past years. It has thus become increasingly necessary to be able to
extract information from incomplete sources: either damaged physical
devices, deliberately erased data, etc. In this context, file carving,
that is, the systematic attempt to recognize data according to some
format specifications, is fundamental.

The current file carving technology used in NFI is the "Metal"
framework, that abstracts the complexities of parsing binary data,
providing a Java API. To date, "Metal" has helped NFI developers to
specify a number of data formats in a more user-friendly manner. There
is, however, some opportunities for improvement. In particular, the way
references are managed within the framework make dependencies difficult
to reason about. Also, by using the API, developers create a layer of
dynamically typed code on top of statically typed Java, which prevents
the detection of type errors at compile time. To minimize these
drawbacks, but at the same time reuse and learn from the effort put into
"Metal", we propose DAN, a typed domain-specific language, sitting on
top of ``Metal'' as a higher level layer of abstraction.

DAN (Domain-specific Language for Anonymization) is a domain-specific
language for parsing binary data and was originally designed for
anonymization of data. In DAN each token definition has its own type.
Users can define new structured types that correspond to parsers, making
the process of encoding new binary specifications less error-prone. To
execute these specifications, DAN generates calls to the "Metal" API,
reusing the knowledge encoded in that library. The present document is
still a draft and explores the main features of the current design of
DAN.

\hypertarget{execution-model}{%
\section{Execution model}\label{execution-model}}

A program consists of one or more modules. A module, thus, starts with a
declaration of its name, followed by the modules it depends on:

\begin{verbatim}
module foo

import bar1
import bar2

...
\end{verbatim}

The body of the module consists of a series of type definitions, that
can be interpreted as parsers. A program starts being executed by
parsing a stream of bytes using a token/type definition, such as:

\begin{verbatim}
struct Name{
    u8[] firstName[20]
    u8[] secondName[20]
}
\end{verbatim}

\texttt{Name} defines a composed type and also specifies a parser. If we
start the execution at \texttt{Name}, the result of that
execution/parsing will be a data structure containing fields
\texttt{firstName} and \texttt{secondName}. Consider another example of
a type definition:

\begin{verbatim}
struct Info{
    Name name
    u8[] email[30]
}
\end{verbatim}

\texttt{Info} defines another type, that depends on \texttt{Name}. If we
start the execution at \texttt{Info}, the result of that execution will
be a data structure containing fields \texttt{name} of the user-defined
type \texttt{Name}, and field \texttt{email} of the primitive type
\texttt{u8{[}{]}}.

\hypertarget{types}{%
\section{Types}\label{types}}

The main metaphor in DAN is that types correspond to parsers. However,
for computation purposes, we also need plain types that are not
associated to any parsing process. Therefore, we can distinguish
non-token types such as \texttt{string}, \texttt{int}, \texttt{bool},
and token types such as \texttt{u8} (unsigned byte), \texttt{s8} (signed
byte), \texttt{u16} (unsigned 16-bit word), \texttt{s128} (unsigned
128-bit word), etc. Both kinds of types can be aggregated in list types,
specified as \texttt{T{[}{]}}, where \texttt{T} is a type, e.g.:
\texttt{int{[}{]}}, \texttt{string{[}{]}}, \texttt{u8{[}{]}}. Notice
that that the latter example is a list that is composed of token types,
and therefore is also considered to be a token type.

Besides the aforementioned primitive types, user can define their own
(token) types via \texttt{struct} or \texttt{choice} declarations.

In this section, we review in detail the available primitive types and
how to define new user-defined types.

\hypertarget{primitive-token-types}{%
\subsection{Primitive token types}\label{primitive-token-types}}

Consider the following field definitions:

\begin{verbatim}
u8 oneUnsignedByte
s8 oneSignedByte
\end{verbatim}

The first component of each definition is the type of the field, in
these cases \texttt{u8} for an unsigned byte and \texttt{s8} for a
signed byte. These definition can also be interpreted as parsers that
will exactly parse 1 byte.

Now consider:

\begin{verbatim}
u16 twoUnignedBytes
u16 twoSignedBytes
\end{verbatim}

They represent a 16-bit word (or a 2-byte word). The \texttt{u} and
\texttt{s} types can be generalized to any multiple of 8, e.g.
\texttt{u256} \texttt{s64}. An alternative way of defining sequential
data is using lists:

\begin{verbatim}
u8[] twoBytes[2]
\end{verbatim}

The first component of this definition is the type of the field, in this
case, a list of unsigned bytes, followed by the name of the field and
then, optionally, the size of the list. In this case, \texttt{twoBytes}
will exactly parse 2 bytes. Alternatively, we can write:

\begin{verbatim}
u8[] aList
\end{verbatim}

Field \texttt{aList} will contain a sequence of bytes of arbitrary
length. (if this is parsed, it will consume all remaining bytes in the
data stream)

Field definitions can also include conditions

\begin{verbatim}
u8 a ?(this != 65)
\end{verbatim}

It defines field \texttt{a} of type \texttt{u8}. The value will only be
assigned if at execution time, the parsed byte is not equal to 65, or,
from another perspective, the parsed character is different from
\texttt{A} (the character corresponding to 65). Notice that the special
variable \texttt{this} in the condition refers to the field currently
being defined.

\emph{TODO: should we discuss the parsing semantics of a failed
condition here?}

\hypertarget{struct-types}{%
\subsection{Struct types}\label{struct-types}}

We know than we can define structured data that enrich the set of
available types with user-defined ones:

\begin{verbatim}
struct Simple{
    u8 first
    u16 second
}
\end{verbatim}

This definition introduces the user-defined type \texttt{Simple}, that
corresponds to a composed type that contains fields first and second.
The double notion of type/parsing is more evident in the case of
structs, in the sense that the fields' order matters. When used as a
specification for parsing, \texttt{Simple} will first parse a byte that
will be assigned to field \texttt{first}, and then two consecutive bytes
that will be assigned to \texttt{second}.

\hypertarget{primitive-non-token-types}{%
\subsection{Primitive non-token types}\label{primitive-non-token-types}}

Not every type is parseable. Non-token types allow us to represent
common primitive values that are not attached to a particular byte
representation, such as strings, integers or booleans. As they do not
define parsers, fields of a non-token type need to be initialized at the
moment of declaration, for example:

\begin{verbatim}
struct Simple{
    int myOne = 1
}
\end{verbatim}

A non-token type can be used to compute derived attributes inside an
user-defined token type:

\begin{verbatim}
struct DerivedExample{
    u8[] token1[3]
    int offset1 = token1.offset
    u8[] token2
    int length2 =  token2.length
}
\end{verbatim}

\textbf{Important:} all list types have an implicit \texttt{length}
field, and all token types, an implicit \texttt{offset} field.

For readability purposes, it is sometimes preferable to separate the
token fields from the derived ones, as the token ones "define" the
parser. To do so, a dependency graph is calculated and therefore
programmers can arrange the derived fields in any order. Coming back to
the previous example, the following struct definitions are two valid
alternative encodings:

\begin{verbatim}
struct DerivedExample2{
    u8[] token1[3]
    u8[] token2
    
    int offset1 = token1.offset
    int length2 = token2.length
}

struct DerivedExample3{
    int offset1 = token1.offset
    int length2 = token2.length
        
    u8[] token1[3]
    u8[] token2
}
\end{verbatim}

\hypertarget{choice-types}{%
\subsection{Choice types}\label{choice-types}}

We can also define choice types:

\begin{verbatim}
struct A{
    u8 content ? (this == "A")
}

struct B{
    u8 content ? (this == "B")
}

choice AB{
    A
    B
}
\end{verbatim}

Choice types imply backtracking. In this case, an attempt to parse the
input with type \texttt{A} will be made first. If this parsing does not
succeed, then \texttt{B} will be tried, in strict declaration order. In
other words, the disambiguation is driven by the parsing process. Note
that the fields in a choice correspond to alternatives, therefore, they
are not named.

Notice too that despite both alternatives featuring a field
\texttt{content} of type \texttt{u8}, this field is not accessible if we
have a reference to a value of type \texttt{AB}. In order to do this, we
need to use \emph{abstract fields}. An abstract field is a field
declared inside a choice, whose implementation is abstract and must be
defined in \emph{each one of the alternatives}. Let us redefine
\texttt{AB} using this concept:

\begin{verbatim}
choice AB2{
    abstract u8 content
    A
    B
}
\end{verbatim}

Since both alternatives have a field called content of type \texttt{u8},
this definition is valid. Thus, \texttt{AB2} exposes a field content
that will hold the proper value, depending on which alternative is going
to be taken.

\hypertarget{implicit-coercions}{%
\subsection{Implicit coercions}\label{implicit-coercions}}

In the previous example, notice the equality check performed in the
\texttt{content} declarations . We are comparing \texttt{this} (which
refers to the field \texttt{content} of type \texttt{u8} with string
literals ("A" and "B"), of type \texttt{string}. This comparison works
because there is an implicit cohercion from the type \texttt{u8} to the
type \texttt{string}. Primitive token types, such as \texttt{u} types,
\texttt{s} types, or list types containing them, can be coerced to
primitive non-token type, such as \texttt{string} or \texttt{int} by
using some implicit encoding conventions. To alter these coventions, we
can use "meta properties", explained below.

\hypertarget{constructors-of-user-defined-types}{%
\subsection{Constructors of user-defined
types}\label{constructors-of-user-defined-types}}

We can modularize programs by having parametric user-defined types:

\begin{verbatim}
struct MustBeOfCertainAge(int ageLimit){
    u8[] name[20]
    u8 age ? (this == ageLimit)
}
\end{verbatim}

In this case, \texttt{MustBeOfCertainAge} acts as a constructor
receiving one integer argument.

In order to build parsers conforming to this definition we need to
parameterize the construction of values of this type. Consider, for
instance, this field declaration:

\begin{verbatim}
MustBeOfCertainAge person(18)
\end{verbatim}

This field definition instantiate the \texttt{MustBeOfCertainAge} struct
definition for the concrete argument \texttt{18}.

\hypertarget{anonymous-fields}{%
\subsection{Anonymous fields}\label{anonymous-fields}}

Sometimes, a field is needed just for parsing purposes but it does not
really need to have a named assigned. In that case, we can use the field
name \texttt{\_}, which means to ignore that field when accessing the
fields of a value of such type:

\begin{verbatim}
struct Ignoring{
       u8[] name[20]
       u8 _ ? (this == ' ') // there must be a space after the name, but we do not name it
       u16 age
       u8[] _[4] ? (this == '     ') // there must be four spaces after the age, but we do not name it
   }
\end{verbatim}

\hypertarget{inline-user-defined-types}{%
\subsection{Inline user-defined types}\label{inline-user-defined-types}}

In the choice example, for defining types \texttt{AB} and \texttt{AB2}
we also needed to define types \texttt{A} and \texttt{B}, exclusively in
order to define the alternatives of the choice. In these situations, it
might be more convenient to inline the struct definitions, as shown
here:

\begin{verbatim}
choice AB3{
    abstract u8 content
    struct{
        u8 content ? (u8 == "A")
    }
    struct{
        u8 content ? (u8 == "B")
    }
}
\end{verbatim}

The same applies for a struct definition, for example:

\begin{verbatim}
struct Info2{
    struct{
        u8[] firstName[20]
        u8[] secondName[20]
    } name
    u8[] email[30]
}
\end{verbatim}

In order to access the \texttt{firstName} field of the inner struct,
assuming that we have a variable \texttt{i} of type \texttt{Info2}, we
need to write \texttt{anInfo2.name.firstName}.

\hypertarget{parsing}{%
\section{Parsing}\label{parsing}}

Sometimes it is necessary to write generic code that is independent of
one specific format specification. In those cases, we want to have
parameterized parsing (\texttt{tie} in metal). For this, we can use the
\texttt{parse} expression, that parses a given list of bytes according
to a token type specified as a type parameter. We have not discussed
type parameters in this document as this is a feature we will add in a
next iteration. Consider this example, illustrating the use of
\texttt{parse}:

\begin{verbatim}
struct Digit{
    u8 a ?(this >=0 || this <=9)
}

struct TwoXs<X>{
    u8[] first
    u8[] second
    X firstX = parse<X>(first)
    X secondX =  parse<X>(second)
}

struct Simple{
    TwoXs<Digit> as
    X oneX = as.firstX
}
\end{verbatim}

\hypertarget{functions}{%
\section{Functions}\label{functions}}

We provide a simple mechanism for reuse through functions. A function
allows to abstract over common pattern of computations. Consider the
standard squaring example:

\begin{verbatim}
int square(int x) = x * x
\end{verbatim}

Having added this definition, we can now reuse this behavior when
defining a type:

\begin{verbatim}
struct Foo{
    u8 bar
    int x2 = square(bar)
}
\end{verbatim}

If more sophisticated behavior is required, we can declare "function
bridges", that is, declare the signature of a function annotated with a
Java implementation:

\begin{verbatim}
@(org.foo.VeryComplexEncoding)
int veryComplexEncoding(int x)

struct Foo2{
    u8 bar
    int x = veryComplexEncoding(bar)
}
\end{verbatim}

\hypertarget{meta-properties}{%
\section{Meta properties}\label{meta-properties}}

Properties that have to do with how to parse the token types are
represented as annotations at the declaration level:

\begin{verbatim}
struct Block@(encoding=LittleIndian){
    u32 content ?(this == 0xDEADBEEF )
    u8[] content[4] ?(this == 0xCAFEBEEF)
}
\end{verbatim}

This means that Little Indian will be the encoding used for parsing
content to produce a value of type \texttt{Block}.

Another meta-property is \texttt{offset}, that creates a new parsing
pointer (disconnected from the context) and moves that parsing pointer
to the specific (absolute) offset. If omitted, the default is to advance
the normal pointer of the parent. Here an example where we start parsing
from the 10th byte on:

\begin{verbatim}
struct Root {
    // parsing pointer is at position 0
    u8 oneByte
    // parsing pointer is at position 1
    u32 oneInt
    // parsing pointer is at position 5
    Block2 sim
    // parsing pointer is at position 5
    Block2 sim
    // parsing pointer is at position 5
    u8 oneByte
    // parsing pointer is at position 6
}

struct Block2@(offset=9){
    // parsing pointer is at position 9
    u8[] content[4]
    // parsing pointer is at position 13
}
\end{verbatim}

\hypertarget{metal-constructs-mapped-to-dan}{%
\section{Metal constructs mapped to
DAN}\label{metal-constructs-mapped-to-dan}}

\hypertarget{tokens}{%
\subsection{Tokens}\label{tokens}}

\renewcommand*{\arraystretch}{1.4}
\begin{longtable}[]{@{}p{5cm} p{4.5cm} p{5.5cm}@{}}
\toprule
Metal shorthand & Description & DAN\tabularnewline
\midrule
\endhead
\texttt{def(name,\ size)} & name a field with a size in bytes &
\texttt{u8{[}{]}\ name{[}size{]}} or \texttt{u32\ name}\tabularnewline
\texttt{nod(size)} & a ignored set of bytes &
\texttt{u8{[}{]}\ \_{[}size{]}}\tabularnewline
\texttt{cho(name,\ list{[}Token{]})} & find the first token that parses
successfully & \texttt{choice\ name\{\ ...\ \}}\tabularnewline
\texttt{rep(name,\ Token)} & name a field that repeats a token until it
fails to parse & \texttt{T{[}{]}\ name}\tabularnewline
\texttt{repn(name,\ Token,\ size)} & name a field that repeats a token n
times & \texttt{T{[}{]}\ name{[}n{]}}\tabularnewline
\texttt{seq(name,\ list{[}Token{]})} & define a sequence of tokens &
\texttt{struct\ name\{\ ...\ \}}\tabularnewline
\texttt{sub(name,\ startAt,\ token)} & parse a token at a specific
offset &
\texttt{struct@(offset=startAt)\ name\ \{\ ...\ \}}\tabularnewline
\texttt{pre(name,\ Token,\ predicate)} & to be determined
&\tabularnewline
\texttt{post(name,\ Token,\ predicate)} &
\texttt{token\ name\ ?(pedicate)} &\tabularnewline
\texttt{whl(name,\ Token,\ predicate)} & to be determined
&\tabularnewline
\texttt{opt(name,\ Token)} & to be determined &\tabularnewline
\texttt{token(name)} & get a reference to a token ``type'' instead of a
value & \texttt{T.type}\tabularnewline
\texttt{tie(name,\ Token,\ data)} & Run a token parser on the result of
a data expression &
\texttt{u8{[}{]}\ name\ =\ parse\textless{}Token\textgreater{}(data)}
(\texttt{Token} is a type parameter representing the token type, while
\texttt{data} corresponds to a list of bytes, having type
\texttt{u8{[}{]}})\tabularnewline
\texttt{until(name,\ initialSize?,\ stepSize?,\ maxSize?,\ terminatorToken)}
& unclear, the size params are all optional &\tabularnewline
\texttt{when(name,\ Token,\ predicate)} & unsure &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{expression}{%
\subsection{Expression}\label{expression}}

\renewcommand*{\arraystretch}{1.4}
\begin{longtable}[]{@{}p{5cm} p{4.5cm} p{5.5cm}@{}}
\toprule
Metal shorthand & Description & DAN\tabularnewline
\midrule
\endhead
\texttt{add} & & \texttt{l\ +\ r}\tabularnewline
\texttt{div} & & \texttt{l\ /\ r}\tabularnewline
\texttt{mul} & & \texttt{l\ *\ r}\tabularnewline
\texttt{sub} & & \texttt{l\ -\ r}\tabularnewline
\texttt{mod} & & \texttt{l\ \%\ r}\tabularnewline
\texttt{neg} & & \texttt{-l}\tabularnewline
\texttt{shl} & & \texttt{l\ \textless{}\textless{}\ r}\tabularnewline
\texttt{shr} & &
\texttt{l\ \textgreater{}\textgreater{}\ r}\tabularnewline
\texttt{and} & binary and & \texttt{l\ \&\ r}\tabularnewline
\texttt{or} & binary or & \texttt{l\ | r}\tabularnewline
\texttt{not} & binary (and boolean) not & \texttt{!l}\tabularnewline
\texttt{and} & boolean and & \texttt{l\ \&\&\ r}\tabularnewline
\texttt{or} & boolean or & \texttt{l\ || r}\tabularnewline
`eq* & comparision operators & default comparison
operators\tabularnewline
\texttt{con} & constants & literal syntax for arbitrary precision ints,
strings, arrays\tabularnewline
\texttt{len(l)} & the size of a token &
\texttt{aToken.size}\tabularnewline
\texttt{ref(name)} & create a list of all instances of something with
that name & \texttt{x.name} (however, it's not dynamic scoping
anymore)\tabularnewline
\texttt{first(l)} & first element of the list/array &
\texttt{l{[}0{]}}\tabularnewline
\texttt{last(l)} & last element of the list/array & \texttt{l{[}-1{]}}
or \texttt{l{[}l.length\ -\ 1{]}}\tabularnewline
\texttt{nth(l,\ i)} & nth element of the list/array &
\texttt{l{[}i{]}}\tabularnewline
\texttt{offset(reference\ name)} & get the absolute offset of something
that has already been parsed & \texttt{n.offset} (without dynamic
scoping aspect)\tabularnewline
\texttt{cat(a,\ b)} & concat the bytes together of two parsed trees &
\texttt{a\ +\ b}\tabularnewline
\texttt{elvis(v,\ orElse)} & still need to design this &\tabularnewline
\texttt{count(t)} & the size of a list &
\texttt{aList.length}\tabularnewline
\texttt{foldLeft(values,\ reducer,\ initial?)} & still need to be
designed &\tabularnewline
\texttt{foldRight(values,\ reducer,\ initial?)} & still need to be
designed &\tabularnewline
\texttt{fold(values,\ reducer,\ initial?)} & still need to be designed &
\texttt{(T\ initial\ \textbar{}\ reducer\ \textbar{}\ x\ \textless{}-\ values)}
(reducer is an expression that has in scope both the special variable
\texttt{it} , representing the accumulator, and variable \texttt{x}
representing the current element being processed; the result of this
expression is of type \texttt{T})\tabularnewline
\texttt{mapLeft(values,\ mapper,\ left,\ rightExpand)} & still need to
be designed &\tabularnewline
\texttt{mapRight(values,\ mapper,\ leftExpand,\ right)} & still need to
be designed &\tabularnewline
\texttt{rev(values)} & reverse a list & still need to be designed, might
be less needed since references aren't lists anymore\tabularnewline
\texttt{exp(base,\ count)} & repeat (expand) \texttt{base}
\texttt{count} times & missing, maybe something with
slices?\tabularnewline
\texttt{bytes(x)} & get the bytes represented by something & automatic
cohercion solves this\tabularnewline
\bottomrule
\end{longtable}
\end{document}
